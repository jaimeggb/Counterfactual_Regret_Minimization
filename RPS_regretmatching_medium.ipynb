{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the following line for both agents to use regret matching and so for the game to reach a Nash Equilibrium:\n",
    "\n",
    "opp_action = random.choices(list(Action), weights=strategy)[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import random\n",
    "from typing import List\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action(Enum):\n",
    "  ROCK = 0\n",
    "  PAPER = 1\n",
    "  SCISSORS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_strategy(cumulative_regrets: np.array) -> np.array:\n",
    "    \"\"\"Return regret-matching strategy\"\"\"\n",
    "    pos_cumulative_regrets = np.maximum(0, cumulative_regrets)\n",
    "    if sum(pos_cumulative_regrets) > 0: \n",
    "        return pos_cumulative_regrets / sum(pos_cumulative_regrets)\n",
    "    else:\n",
    "        return np.full(shape=len(Action), fill_value=1/len(Action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_payoff(action_1: Action, action_2: Action) -> int:\n",
    "    \"\"\"Returns the payoff for player 1\"\"\"\n",
    "    mod3_val = (action_1.value - action_2.value) % 3\n",
    "    if mod3_val == 2:\n",
    "        return -1\n",
    "    else:\n",
    "        return mod3_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regrets(payoff: int, action_2: Action) -> List[int]:\n",
    "    \"\"\"return regrets\"\"\"\n",
    "    return np.array([get_payoff(a, action_2) - payoff for a in Action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 10000\n",
    "cumulative_regrets = np.zeros(shape=(len(Action)), dtype=int)\n",
    "strategy_sum = np.zeros(shape=(len(Action)))\n",
    "opp_strategy = [0.5, 0.2, 0.3]\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    #  compute the strategy according to regret matching\n",
    "    strategy = get_strategy(cumulative_regrets)\n",
    "\n",
    "    #  add the strategy to our running total of strategy probabilities\n",
    "    strategy_sum += strategy\n",
    "    \n",
    "    # Choose our action and our opponent's action\n",
    "    our_action = random.choices(list(Action), weights=strategy)[0]\n",
    "    opp_action = random.choices(list(Action), weights=strategy)[0] # weights=opp_strategy) for both agents to use the regret matching strategy\n",
    "    \n",
    "    #  compute the payoff and regrets\n",
    "    our_payoff = get_payoff(our_action, opp_action)\n",
    "    regrets = get_regrets(our_payoff, opp_action)\n",
    "    \n",
    "    #  add regrets from this round to the cumulative regrets\n",
    "    cumulative_regrets += regrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33389733 0.33487117 0.33123149]\n"
     ]
    }
   ],
   "source": [
    "optimal_strategy = strategy_sum / num_iterations\n",
    "print(optimal_strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e62dcc45d4cf21a563dc8c58b679171a51000e7c290e6a36376a6644d2c9a33b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
